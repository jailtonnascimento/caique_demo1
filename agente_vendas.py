# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import json

# -*- coding: utf-8 -*-

import openai
import json
import os
from typing import Dict, Any


import google.generativeai as genai
 
 
 

from dotenv import load_dotenv

# Defina sua chave da API OpenAI aqui
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=GOOGLE_API_KEY)

os.environ["DEEPSEEK_API_KEY"] = os.getenv("DEEPSEEK_API_KEY")



# 1. Leitura do CSV
file_path = '../Bases/BI-NNP_2025.csv'  # Ajuste o caminho conforme necess√°rio

# Usando latin1 para evitar problemas com acentos comuns em arquivos brasileiros
df = pd.read_csv(file_path, sep=';', encoding='latin1', dtype=str)

print("‚úÖ Arquivo carregado com sucesso!")
print(f"üìä Dimens√µes: {df.shape[0]} linhas, {df.shape[1]} colunas\n")

# 2. Fun√ß√£o para converter string para float (substitui v√≠rgula por ponto)
def str_to_float(x):
    if pd.isna(x):
        return np.nan
    try:
        return float(x.replace(',', '.'))
    except:
        return np.nan

# 3. Colunas a serem convertidas para num√©ricas
cols_to_float = [
    'Quant. Fatur', 'Vlr. Total', 'Vl IPI', 'Vl PIS', 'Vl COFINS', 'Vl ICM Item',
    'Unit. Net', 'Unit. Bruto', 'Valor Mat', 'Valor GGF', 'CPV - Total', 'CPV - Unit',
    'Vlr Total L√≠quido', 'Margem %', 'Marg. Bruta', '% M.P.', 'Cotacao', 'Unit Dolar', 'Total Dolar'
]

for col in cols_to_float:
    if col in df.columns:
        df[col] = df[col].apply(str_to_float)

# Remover linhas com valores cr√≠ticos nulos
df.dropna(subset=['Vlr. Total', 'CPV - Total', 'Vlr Total L√≠quido'], inplace=True)

# 4. C√°lculos adicionais
df['Lucro (R$)'] = df['Vlr Total L√≠quido'] - df['CPV - Total']
df['Pre√ßo M√©dio'] = df['Vlr. Total'] / df['Quant. Fatur']
df['Markup'] = df['Pre√ßo M√©dio'] / df['CPV - Unit']

# Classifica√ß√£o de margem
def classificar_margem(margem):
    if margem < 0: return 'üî¥ Negativa'
    elif margem < 10: return 'üü° Muito Baixa'
    elif margem < 30: return 'üü† Baixa'
    elif margem < 50: return 'üü¢ M√©dia'
    else: return 'üîµ Alta'

df['Categoria Margem'] = df['Margem %'].apply(classificar_margem)

# ===================================================================================
# NOVA FUN√á√ÉO: Gerar JSON Estrat√©gico para LLM (OpenAI)
# Este JSON ser√° enviado √† LLM para gerar an√°lise narrativa de alto impacto
# ===================================================================================

def gerar_json_para_llm(df):
    """
    Gera um JSON estruturado com m√©tricas e insights para an√°lise por LLM.
    O formato √© claro, conciso e rico em contexto estrat√©gico.
    """
    faturamento_total = float(df['Vlr. Total'].sum())
    lucro_bruto_total = float(df['Lucro (R$)'].sum())
    margem_media = (lucro_bruto_total / df['Vlr Total L√≠quido'].sum()) * 100 if df['Vlr Total L√≠quido'].sum() != 0 else 0

    # Top 3 clientes
    top_clientes = df.groupby('Nome Cliente')['Vlr. Total'].sum().sort_values(ascending=False).head(3)
    clientes_lista = [
        {"cliente": cliente, "faturamento_r$": round(float(valor), 2)} 
        for cliente, valor in top_clientes.items()
    ]

    # Desempenho por gestor
    desempenho_gestores = df.groupby('Gestor de Contas')['Vlr. Total'].sum().sort_values(ascending=False)
    gestores_lista = [
        {"gestor": gestor, "faturamento_r$": round(float(valor), 2)}
        for gestor, valor in desempenho_gestores.items()
    ]

    # Concentra√ß√£o de receita
    concentracao_top3 = (top_clientes.sum() / faturamento_total) * 100

    # Exporta√ß√µes
    exporta = df[df['Pais'] != 'BRASIL']
    exportacoes = {
        "total_r$": float(exporta['Vlr. Total'].sum()) if not exporta.empty else 0,
        "paises": exporta['Pais'].unique().tolist() if not exporta.empty else []
    }

    # Alertas: vendas com preju√≠zo
    margem_neg = df[df['Margem %'] < 0]
    alertas_prejuizo = []
    for _, row in margem_neg.iterrows():
        alertas_prejuizo.append({
            "cliente": row['Nome Cliente'],
            "produto": row['Descri√ß√£o'],
            "nota_fiscal": row['Nr. Nota'],
            "prejuizo_r$": round(float(row['Lucro (R$)']), 2),
            "margem_%": round(float(row['Margem %']), 2)
        })

    # Oportunidades: produtos com alta margem (>50%)
    alta_margem = df[df['Margem %'] > 50]
    produtos_alta_margem = []
    for _, row in alta_margem.iterrows():
        produtos_alta_margem.append({
            "produto": row['Descri√ß√£o'],
            "cliente": row['Nome Cliente'],
            "margem_%": round(float(row['Margem %']), 2),
            "faturamento_r$": round(float(row['Vlr. Total']), 2),
            "segmento": row['Segmentacao']
        })

    # Cross-sell: padr√µes de compra por segmento
    segmentos = df.groupby('Segmentacao')['Familia Comercial Descricao'].value_counts().to_dict()
    oportunidades_cross_sell = []
    if 'Print' in segmentos:
        oportunidades_cross_sell.append({
            "recomendacao": "Clientes do segmento Print (como DIGITO e SINALFIX) compram produtos cristal (PR-CLEAR), mas podem estar abertos ao PR-WHITE. Alta chance de convers√£o.",
            "segmento": "Print",
            "produtos_relacionados": ["PR-CLEAR", "PR-WHITE"]
        })
    if 'Pharma/Nutra/Vet' in segmentos:
        oportunidades_cross_sell.append({
            "recomendacao": "Clientes Pharma (CIMED, EPNB) consomem PH-CLEAR. Oportunidade de upsell com linhas especiais (UV, termoform√°veis).",
            "segmento": "Pharma/Nutra/Vet",
            "produtos_relacionados": ["PH-CLEAR", "PH-UV"]
        })

    # Estrutura final do JSON
    relatorio_json = {
        "periodo_analisado": "Janeiro/2025",
        "metricas_gerais": {
            "faturamento_total_r$": round(faturamento_total, 2),
            "lucro_bruto_total_r$": round(lucro_bruto_total, 2),
            "margem_media_%": round(margem_media, 1),
            "numero_clientes_unicos": int(df['Nome Cliente'].nunique()),
            "concentracao_receita_top3_clientes_%": round(concentracao_top3, 1)
        },
        "desempenho": {
            "top_3_clientes_por_faturamento": clientes_lista,
            "desempenho_por_gestor": gestores_lista,
            "exportacoes": exportacoes
        },
        "oportunidades": {
            "produtos_com_margem_acima_de_50%": produtos_alta_margem,
            "potenciais_de_cross_sell_e_upsell": oportunidades_cross_sell
        },
        "riscos_criticos": {
            "vendas_com_prejuizo": alertas_prejuizo,
            "observacoes": "Venda com margem negativa representa perda direta de caixa. Revisar pol√≠tica de descontos e forma√ß√£o de pre√ßo."
        }
    }

    return relatorio_json

# ================================
# EXECU√á√ÉO DA FUN√á√ÉO
# ================================




def chamar_llm_openai(prompt: str, modelo: str = "gpt-4o-mini", temperatura: float = 0.7) -> Dict[str, Any]:
    """
    Fun√ß√£o dedicada √† chamada da API da OpenAI.
    
    Args:
        prompt (str): O texto completo a ser enviado √† LLM.
        modelo (str): Modelo da OpenAI (ex: gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo)
        temperatura (float): Criatividade da resposta (0 = determin√≠stico, 1 = criativo)
    
    Returns:
        Dict com 'sucesso', 'resposta', e opcionalmente 'erro'
    """
    try:
        resposta = openai.ChatCompletion.create(
            model=modelo,
            messages=[
                {
                    "role": "system",
                    "content": "Voc√™ √© um Diretor Comercial S√™nior. Analise os dados e gere um relat√≥rio executivo claro, estrat√©gico e acion√°vel. Fale diretamente com gestores e CEO. Use linguagem impactante, mas baseada em dados. Evite jarg√µes t√©cnicos sem explica√ß√£o."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=temperatura,
            max_tokens=1500,
            response_format={"type": "text"}  # Pode ser JSON se quiser resposta estruturada
        )
        texto_resposta = resposta.choices[0].message['content'].strip()
        return {
            "sucesso": True,
            "resposta": texto_resposta
        }
    except Exception as e:
        return {
            "sucesso": False,
            "erro": str(e)
        }
    

def chamar_llm_gemini(prompt: str, modelo: str = "gemini-2.5-flash-lite", temperatura: float = 0.7) -> Dict[str, Any]:
    """
    Fun√ß√£o dedicada √† chamada da API do Google Gemini.
    
    Args:
        prompt (str): O prompt completo a ser enviado √† LLM.
        modelo (str): Modelo Gemini (ex: gemini-1.5-pro, gemini-1.0-pro)
        temperatura (float): Controle de criatividade (0 a 1)
    
    Returns:
        Dict com 'sucesso', 'resposta' e opcionalmente 'erro'
    """
    try:
        # Carregar o modelo
        model = genai.GenerativeModel(model_name=modelo)
        
        # Configurar gera√ß√£o
        config = genai.types.GenerationConfig(
            temperature=temperatura,
            max_output_tokens=1500
        )
        
        # Enviar prompt
        response = model.generate_content(
            contents=prompt,
            generation_config=config
        )
        
        return {
            "sucesso": True,
            "resposta": response.text.strip()
        }
    
    except Exception as e:
        return {
            "sucesso": False,
            "erro": str(e)
        }
    
def gerar_prompt_analise_executiva(dados_json: Dict) -> str:
    """
    Transforma o JSON de insights em um prompt poderoso para a LLM.
    """
    prompt = """
Analise profundamente os dados de vendas abaixo e gere um **relat√≥rio executivo de alto impacto**, como se fosse apresentar ao CEO e gestores de vendas.

üìå Instru√ß√µes:
- Use um **t√≠tulo impactante** no in√≠cio.
- Destaque **3 conquistas estrat√©gicas**.
- Exponha **2 riscos cr√≠ticos** com dados concretos.
- Aponte **3 oportunidades reais de crescimento imediato** (cross-sell, exporta√ß√£o, margem).
- D√™ **recomenda√ß√µes espec√≠ficas por gestor de conta**.
- Use linguagem clara, direta, com senso de urg√™ncia.
- Nada de "Ol√°, aqui est√£o os dados...". V√° direto ao ponto.
- Evite termos gen√©ricos como "melhorar performance". Seja acion√°vel.

üìä DADOS PARA AN√ÅLISE:
""" + json.dumps(dados_json, indent=2, ensure_ascii=False)

    return prompt


relatorio_json = gerar_json_para_llm(df)

# Salvar o JSON para inspe√ß√£o ou envio √† LLM
with open('relatorio_para_llm.json', 'w', encoding='utf-8') as f:
    json.dump(relatorio_json, f, indent=2, ensure_ascii=False)

print("üìÑ JSON estrat√©gico gerado com sucesso!")
print("üìÅ Arquivo salvo como 'relatorio_para_llm.json'")
print("\nüí° Pr√≥ximo passo: envie este JSON para uma LLM (ex: GPT-4) com um prompt poderoso para gerar a an√°lise executiva.")

# Exibir uma pr√©via (opcional)
print("\nüîç Pr√©via do JSON (primeiros 500 caracteres):")
print(json.dumps(relatorio_json, indent=2, ensure_ascii=False)[:500] + "...")

# 1. Gerar o JSON com insights
relatorio_json = gerar_json_para_llm(df)

# 2. Gerar o prompt para a LLM
prompt = gerar_prompt_analise_executiva(relatorio_json)

# 3. Chamar a OpenAI
print("\nüöÄ Enviando an√°lise para a OpenAI...")
resposta_llm = chamar_llm_gemini(prompt, modelo="gemini-2.5-flash-lite", temperatura=0.7)

if resposta_llm["sucesso"]:
    print("\nüí° AN√ÅLISE DA LLM (OpenAI):\n")
    print(resposta_llm["resposta"])
    
    # Salvar resultado
    with open('analise_executiva_openai.txt', 'w', encoding='utf-8') as f:
        f.write(resposta_llm["resposta"])
    print("\n‚úÖ An√°lise salva em 'analise_executiva_openai.txt'")
else:
    print(f"‚ùå Erro ao chamar OpenAI: {resposta_llm['erro']}")
